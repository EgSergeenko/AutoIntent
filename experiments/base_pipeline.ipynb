{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/classification_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first one need to split data to train and test and then launch client with vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': 'activate_my_card',\n",
       " 'sample_utterances': [\"Please help me with my card.  It won't activate.\",\n",
       "  'I tired but an unable to activate my card.',\n",
       "  'I want to start using my card.',\n",
       "  'How do I verify my new card?',\n",
       "  \"I tried activating my plug-in and it didn't piece of work\"],\n",
       " 'regexp_for_sampling': [],\n",
       " 'regexp_as_rules': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "banking77 = json.load(open('../data/intent_records/banking77.json'))\n",
    "banking77[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import DataHandler\n",
    "\n",
    "data_handler = DataHandler(banking77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler.delete_collection(db_name=\"example_collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': 'what_are_you_talking_about',\n",
       " 'sample_utterances': [],\n",
       " 'regexp_for_sampling': ['(alexa ){0,1}what are ((you)|(we)) ((talking about)|(discussing))',\n",
       "  '(alexa ){0,1}what ((you)|(we)) are (even ){0,1}((talking about)|(discussing))',\n",
       "  '(alexa ){0,1}what does it mean',\n",
       "  '(alexa ){0,1}pass that by me again',\n",
       "  \"(alexa ){0,1}i ((don't)|(didn't)|(do not)|(did not)) get it\",\n",
       "  '(alexa ){0,1}what it is about',\n",
       "  '(alexa ){0,1}what is it about',\n",
       "  'i lost common ground',\n",
       "  '(alexa ){0,1}what (even ){0,1}is that',\n",
       "  \"(i ((did not get)|(don't understand)|(don't get)) ){0,1}what do you mean( alexa){0,1}\",\n",
       "  \"(sorry, ){0,1}i ((don't)|(do not)|(didn't)|(did not)) ((understand)|(get))( ((what you mean)|(what are you talking about)))( alexa){0,1}\",\n",
       "  '((what you mean)|(what are you talking about))( alexa){0,1}',\n",
       "  \"i don't know what you just said\"],\n",
       " 'regexp_as_rules': ['(alexa ){0,1}are we having a communication problem',\n",
       "  \"(alexa ){0,1}i don't think you understand\",\n",
       "  'what',\n",
       "  'I did not get what do you mean']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dream = json.load(open('../data/intent_records/dream.json'))\n",
    "dream[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def regexp(utterance: str, intents_patterns: list[dict]):\n",
    "    detected = set()\n",
    "    for intent in intents_patterns:\n",
    "        for pattern in intent['regexp_for_sampling'] + intent['regexp_as_rules']:\n",
    "            if re.match(pattern, utterance) is None:\n",
    "                continue\n",
    "            detected.add(intent['intent_id'])\n",
    "    return detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 5}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp(\n",
    "    utterance='what are you talking about',\n",
    "    intents_patterns=dream\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp(\n",
    "    utterance='tell me something else',\n",
    "    intents_patterns=dream\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp(\n",
    "    utterance='kind of',\n",
    "    intents_patterns=dream\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voorhs/.pyenv/versions/3.10.14/envs/.autointent-dev/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from src.modules import VectorDBModule\n",
    "\n",
    "vectordb = VectorDBModule(model_name='infgrad/stella-base-en-v2', k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name infgrad/stella-base-en-v2. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "vectordb.fit(data_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modules:\n",
    "- knn\n",
    "- linear\n",
    "- dnnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules import KNNScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0. , 0.1,\n",
       "        0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0.2, 0.1, 0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0.1,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0.2, 0.2, 0. , 0. , 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_scorer = KNNScorer(k=10)\n",
    "knn_scorer.fit(data_handler)\n",
    "knn_scorer.predict(['i want a new card', 'new card please'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 39,  0],\n",
       "       [11, 40, 39]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_scorer.predict_topk(['i want a new card', 'new card please'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules import LinearScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voorhs/.pyenv/versions/3.10.14/envs/.autointent-dev/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "linear_scorer = LinearScorer()\n",
    "linear_scorer.fit(data_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.06857367e-02, 4.16150564e-03, 1.37571193e-03, 6.29149965e-03,\n",
       "        2.06469180e-03, 9.78793881e-04, 8.17828404e-04, 1.14443451e-03,\n",
       "        4.47680380e-03, 1.59703771e-01, 3.27302955e-02, 1.52204605e-02,\n",
       "        2.71018459e-02, 1.92528275e-02, 8.30385490e-02, 7.42028009e-03,\n",
       "        1.51428275e-03, 3.00459763e-03, 4.10515740e-03, 4.57421712e-04,\n",
       "        1.82732687e-03, 1.00036981e-02, 2.43404716e-03, 1.92502069e-02,\n",
       "        1.40963900e-02, 1.64224361e-02, 5.50657899e-04, 1.52087228e-03,\n",
       "        4.12858346e-03, 1.20586539e-02, 2.19611457e-02, 8.55034389e-04,\n",
       "        1.28547936e-03, 3.52925538e-03, 1.38407059e-03, 1.31016307e-03,\n",
       "        1.24381276e-03, 1.26546543e-02, 4.28389326e-03, 1.16650568e-01,\n",
       "        6.74566349e-02, 9.86701907e-02, 2.27468386e-03, 4.96292450e-02,\n",
       "        1.36061695e-03, 7.51627122e-04, 9.67389846e-04, 2.57934135e-03,\n",
       "        2.31915731e-04, 2.08830240e-03, 1.11843217e-03, 2.36497811e-03,\n",
       "        5.91962170e-03, 2.67785402e-03, 2.77533925e-03, 6.64202444e-03,\n",
       "        6.28721259e-04, 5.70707973e-03, 3.02124650e-03, 5.45242769e-04,\n",
       "        2.04499980e-03, 7.12848418e-04, 9.43961958e-03, 1.25667632e-02,\n",
       "        4.79146519e-04, 9.66364263e-04, 1.12246310e-03, 7.93495789e-04,\n",
       "        2.64544859e-03, 1.20333212e-03, 1.34199191e-03, 7.18663980e-03,\n",
       "        1.76905082e-03, 2.13920559e-02, 2.16101582e-03, 3.19870229e-03,\n",
       "        5.68129348e-04],\n",
       "       [2.95626294e-02, 5.25253609e-03, 1.01677109e-03, 4.38384640e-03,\n",
       "        2.46166292e-03, 2.67460432e-03, 9.36605502e-04, 9.34479530e-04,\n",
       "        4.27936689e-03, 9.91278125e-02, 2.34884839e-02, 1.67175437e-02,\n",
       "        3.94806436e-02, 2.07621790e-02, 4.07330151e-02, 3.26908075e-03,\n",
       "        9.18898736e-04, 3.47955811e-03, 1.27229612e-03, 2.57857273e-04,\n",
       "        1.72089183e-03, 6.58996623e-03, 1.79491920e-03, 1.90730772e-02,\n",
       "        1.81575636e-02, 8.82031244e-03, 4.47699425e-04, 4.72641262e-03,\n",
       "        2.10805292e-03, 8.96267630e-03, 2.59141239e-02, 1.12443651e-03,\n",
       "        3.01851272e-03, 3.21555833e-03, 1.29648988e-03, 3.05476383e-03,\n",
       "        1.86505739e-03, 6.58231287e-03, 7.77888564e-03, 2.34467254e-01,\n",
       "        1.07820257e-01, 8.99653401e-02, 1.68373223e-03, 4.67806701e-02,\n",
       "        8.41346535e-04, 1.38744391e-03, 9.82549968e-04, 2.69883657e-03,\n",
       "        9.02909089e-04, 1.42623350e-03, 2.61456116e-03, 4.01437254e-03,\n",
       "        2.80200952e-03, 8.06908627e-04, 2.46475038e-03, 3.75269342e-03,\n",
       "        1.85766642e-03, 1.06427321e-02, 3.89471313e-03, 7.16137531e-04,\n",
       "        4.25303092e-03, 1.36840688e-03, 3.60426410e-03, 7.97307247e-03,\n",
       "        6.89728770e-04, 8.08648956e-04, 4.86746832e-03, 9.20177092e-04,\n",
       "        3.32875875e-03, 8.31564177e-04, 9.72255326e-04, 4.89332868e-03,\n",
       "        1.77128278e-03, 9.42194858e-03, 1.26270684e-03, 2.98459382e-03,\n",
       "        2.64062114e-04]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_scorer.predict(['i want a new card', 'new card please'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 39, 41, 14, 40],\n",
       "       [39, 40,  9, 41, 43]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_scorer.predict_topk(['i want a new card', 'new card please'], k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules import DNNCScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnc_scorer = DNNCScorer(model_name=\"BAAI/bge-reranker-base\", k=10)\n",
    "dnnc_scorer.fit(data_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.99912232, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.97535545, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnc_scorer.predict(['i want a new card', 'new card please'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43],\n",
       "       [43]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnc_scorer.predict_topk(['i want a new card', 'new card please'], k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules import ThresholdModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_predictor = ThresholdModule(single_thresh=True)\n",
    "threshold_predictor.fit(data_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 77)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_scores = linear_scorer.predict(['i want a new card', 'new card please'])\n",
    "print(linear_scores.shape)\n",
    "threshold_predictor.predict(linear_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5833333333333333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import retrieval_map\n",
    "\n",
    "y_true = 1\n",
    "y_pred = [2,1,1]\n",
    "\n",
    "retrieval_map([y_true], [y_pred], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Arguments\n",
      "    ---\n",
      "    - `query_labels`: for each query, this list contains its class labels\n",
      "    - `candidates_labels`: for each query, these lists contain class labels of items ranked by a retrieval model (from most to least relevant)\n",
      "    - `k`: the number of top items to consider for each query\n",
      "\n",
      "    Return\n",
      "    ---\n",
      "    retrieval metric, averaged over all queries\n",
      "    \n",
      "\n",
      "    TODO:\n",
      "    - implement multilabel case, where query_labels: list[list[int]], i.e. each query has multiple intents\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(retrieval_map.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import retrieval_hit_rate\n",
    "\n",
    "query_labels = [1]\n",
    "candidates_labels = [[1, 4, 5, 2]]\n",
    "k = 2\n",
    "\n",
    "retrieval_hit_rate(query_labels, candidates_labels, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import retrieval_precision\n",
    "\n",
    "query_labels = [1]\n",
    "candidates_labels = [[1, 1, 3, 4, 5]]\n",
    "k = 3\n",
    "\n",
    "retrieval_precision(query_labels, candidates_labels, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9197207891481876"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import retrieval_ndcg\n",
    "\n",
    "query_labels = [1]\n",
    "candidates_labels = [[1, 2, 1, 2, 5]]\n",
    "k = 3\n",
    "\n",
    "retrieval_ndcg(query_labels, candidates_labels, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import retrieval_mrr\n",
    "\n",
    "query_labels = [1]\n",
    "candidates_labels = [[2, 2, 1, 2, 5]]\n",
    "\n",
    "retrieval_mrr(query_labels, candidates_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5108256237659907"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import scoring_neg_cross_entropy\n",
    "\n",
    "scores = [[0.1, 0.6, 0.3]]\n",
    "labels = [1]\n",
    "\n",
    "scoring_neg_cross_entropy(scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import scoring_roc_auc\n",
    "\n",
    "scores = [[0.1, 0.6, 0.3],[0.1, 0.6, 0.3],[0.1, 0.6, 0.3]]\n",
    "labels = [1, 2, 0]\n",
    "\n",
    "scoring_roc_auc(scores, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.metrics import prediction_accuracy\n",
    "\n",
    "y_true = [1,2,3]\n",
    "y_pred = [1,1,3]\n",
    "\n",
    "prediction_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nodes import RetrievalNode\n",
    "\n",
    "# retrieval_node = RetrievalNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".autointent-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

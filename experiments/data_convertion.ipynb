{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Convertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code for converting different datasets to a my format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir ../data/intent_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source:\n",
    "- english https://github.com/deeppavlov/dream/blob/new_intents/annotators/IntentCatcherTransformers/intent_phrases.json\n",
    "- russian https://github.com/deeppavlov/dream/blob/new_intents/annotators/IntentCatcherTransformers/intent_phrases_RU.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dream = json.load(open('../data/dream.json'))\n",
    "ru_dream = json.load(open('../data/ru_dream.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dream(dream_dict):\n",
    "    res = []\n",
    "    for i, (intent_name, all_phrases) in enumerate(dream_dict['intent_phrases'].items()):\n",
    "        intent_record = dict(\n",
    "            intent_id=i,\n",
    "            intent_name=intent_name,\n",
    "            sample_utterances=[],\n",
    "            regexp_for_sampling=all_phrases['phrases'],\n",
    "            regexp_as_rules=all_phrases['reg_phrases'] if 'reg_phrases' in all_phrases else []\n",
    "        )\n",
    "        res.append(intent_record)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dream_records = convert_dream(dream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_id</th>\n",
       "      <th>intent_name</th>\n",
       "      <th>sample_utterances</th>\n",
       "      <th>regexp_for_sampling</th>\n",
       "      <th>regexp_as_rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what_are_you_talking_about</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(alexa ){0,1}what are ((you)|(we)) ((talking ...</td>\n",
       "      <td>[(alexa ){0,1}are we having a communication pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>topic_switching</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(that's ){0,1}enough( talking ){0,1} about ((...</td>\n",
       "      <td>[tell me something else, don't tell me about ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lets_chat_about</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(stop ){0,1}(((let's )|(i want to )|(wanna )|...</td>\n",
       "      <td>[.*let(('s)|(s)) ((chat)|(talk)) ((to|with) (m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>exit</td>\n",
       "      <td>[]</td>\n",
       "      <td>[be quiet, (see you ){0,1}later, leave me alon...</td>\n",
       "      <td>[(leave|end) (the|this) conversation, alexa do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tell_me_a_story</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tell me ((another)|(other)) story, ((can you ...</td>\n",
       "      <td>[(can you ){0,1}tell me a .* story]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>repeat</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i did not hear you, what come again, what did...</td>\n",
       "      <td>[one second, what( (book|movie))?, say it agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>yes</td>\n",
       "      <td>[]</td>\n",
       "      <td>[yes yes yes, ((sure)|(fine)|(okay)|(ok)|(yes)...</td>\n",
       "      <td>[you bet, kind of, sort of, oh yeah, maybe, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>no</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(alexa ){0,1}((no)|(nope)|(no way)|(don't)|(d...</td>\n",
       "      <td>[.* no no, .* not today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>dont_understand</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(because ){0,1}you are being confusing(, alex...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>stupid</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(alexa ){0,1}why are you this ((stupid)|(dump...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>cant_do</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(alexa ){0,1}sing me a ((happy)|(sad)|(bedtim...</td>\n",
       "      <td>[(let's|let us) play .*, can you whisper.*, (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>tell_me_more</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((please )|(well )){0,1}tell me ((anything )|...</td>\n",
       "      <td>[((please) |(well )){0,1}tell me ((more)|(some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>weather_forecast_intent</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tell me the weather in my ((town)|(city)|(pla...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>what_is_your_name</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((let's )|(please )|(i want you to )){0,1}int...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>where_are_you_from</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Where are you from(, Alexa){0,1}, (((I live i...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>what_can_you_do</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((so )){0,1}(tell me ){0,1}what can you do, (...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>choose_topic</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(tell me ){0,1}what do you ((wanna)|(want to)...</td>\n",
       "      <td>[(tell me ){0,1}what do you ((wanna)|(want to)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>who_made_you</td>\n",
       "      <td>[]</td>\n",
       "      <td>[who ((did)|(created)|(made)|(make)|(create)|(...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>what_is_your_job</td>\n",
       "      <td>[]</td>\n",
       "      <td>[what('s){0,1} is your ((profession)|(job)|(wo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>opinion_request</td>\n",
       "      <td>[]</td>\n",
       "      <td>[what (do){0,1} you ((think)|(reckon)|(believe...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>doing_well</td>\n",
       "      <td>[]</td>\n",
       "      <td>[doing ((fine)|(great)|(cool)|(okay))( ((thank...</td>\n",
       "      <td>[i am good]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>what_time</td>\n",
       "      <td>[]</td>\n",
       "      <td>[can you tell me the time, what(('s)|( is)|())...</td>\n",
       "      <td>[what time is it( in)?[\\s\\S]+, what time it is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    intent_id                 intent_name sample_utterances  \\\n",
       "0           0  what_are_you_talking_about                []   \n",
       "1           1             topic_switching                []   \n",
       "2           2             lets_chat_about                []   \n",
       "3           3                        exit                []   \n",
       "4           4             tell_me_a_story                []   \n",
       "5           5                      repeat                []   \n",
       "6           6                         yes                []   \n",
       "7           7                          no                []   \n",
       "8           8             dont_understand                []   \n",
       "9           9                      stupid                []   \n",
       "10         10                     cant_do                []   \n",
       "11         11                tell_me_more                []   \n",
       "12         12     weather_forecast_intent                []   \n",
       "13         13           what_is_your_name                []   \n",
       "14         14          where_are_you_from                []   \n",
       "15         15             what_can_you_do                []   \n",
       "16         16                choose_topic                []   \n",
       "17         17                who_made_you                []   \n",
       "18         18            what_is_your_job                []   \n",
       "19         19             opinion_request                []   \n",
       "20         20                  doing_well                []   \n",
       "21         21                   what_time                []   \n",
       "\n",
       "                                  regexp_for_sampling  \\\n",
       "0   [(alexa ){0,1}what are ((you)|(we)) ((talking ...   \n",
       "1   [(that's ){0,1}enough( talking ){0,1} about ((...   \n",
       "2   [(stop ){0,1}(((let's )|(i want to )|(wanna )|...   \n",
       "3   [be quiet, (see you ){0,1}later, leave me alon...   \n",
       "4   [tell me ((another)|(other)) story, ((can you ...   \n",
       "5   [i did not hear you, what come again, what did...   \n",
       "6   [yes yes yes, ((sure)|(fine)|(okay)|(ok)|(yes)...   \n",
       "7   [(alexa ){0,1}((no)|(nope)|(no way)|(don't)|(d...   \n",
       "8   [(because ){0,1}you are being confusing(, alex...   \n",
       "9   [(alexa ){0,1}why are you this ((stupid)|(dump...   \n",
       "10  [(alexa ){0,1}sing me a ((happy)|(sad)|(bedtim...   \n",
       "11  [((please )|(well )){0,1}tell me ((anything )|...   \n",
       "12  [tell me the weather in my ((town)|(city)|(pla...   \n",
       "13  [((let's )|(please )|(i want you to )){0,1}int...   \n",
       "14  [Where are you from(, Alexa){0,1}, (((I live i...   \n",
       "15  [((so )){0,1}(tell me ){0,1}what can you do, (...   \n",
       "16  [(tell me ){0,1}what do you ((wanna)|(want to)...   \n",
       "17  [who ((did)|(created)|(made)|(make)|(create)|(...   \n",
       "18  [what('s){0,1} is your ((profession)|(job)|(wo...   \n",
       "19  [what (do){0,1} you ((think)|(reckon)|(believe...   \n",
       "20  [doing ((fine)|(great)|(cool)|(okay))( ((thank...   \n",
       "21  [can you tell me the time, what(('s)|( is)|())...   \n",
       "\n",
       "                                      regexp_as_rules  \n",
       "0   [(alexa ){0,1}are we having a communication pr...  \n",
       "1   [tell me something else, don't tell me about ....  \n",
       "2   [.*let(('s)|(s)) ((chat)|(talk)) ((to|with) (m...  \n",
       "3   [(leave|end) (the|this) conversation, alexa do...  \n",
       "4                 [(can you ){0,1}tell me a .* story]  \n",
       "5   [one second, what( (book|movie))?, say it agai...  \n",
       "6   [you bet, kind of, sort of, oh yeah, maybe, it...  \n",
       "7                            [.* no no, .* not today]  \n",
       "8                                                  []  \n",
       "9                                                  []  \n",
       "10  [(let's|let us) play .*, can you whisper.*, (c...  \n",
       "11  [((please) |(well )){0,1}tell me ((more)|(some...  \n",
       "12                                                 []  \n",
       "13                                                 []  \n",
       "14                                                 []  \n",
       "15                                                 []  \n",
       "16  [(tell me ){0,1}what do you ((wanna)|(want to)...  \n",
       "17                                                 []  \n",
       "18                                                 []  \n",
       "19                                                 []  \n",
       "20                                        [i am good]  \n",
       "21  [what time is it( in)?[\\s\\S]+, what time it is...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_records(dream_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(dream_records, open('../data/intent_records/dream.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_id</th>\n",
       "      <th>intent_name</th>\n",
       "      <th>sample_utterances</th>\n",
       "      <th>regexp_for_sampling</th>\n",
       "      <th>regexp_as_rules</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>what_are_you_talking_about</td>\n",
       "      <td>[]</td>\n",
       "      <td>[о ((чем)|(чём)) ты( говоришь){0,1}( вообще){0...</td>\n",
       "      <td>[о ((чем)|(чём)) ты( говоришь){0,1}( вообще){0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>topic_switching</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((хватит)|(прекрати)|(не хочу)|(не хочу больш...</td>\n",
       "      <td>[((хватит)|(прекрати)|(не хочу)|(не хочу больш...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lets_chat_about</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((можем)|(можешь)|(давай))(( мы)|( ты)|( я)){...</td>\n",
       "      <td>[((можем)|(можешь)|(давай))(( мы)|( ты)|( я)){...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>exit</td>\n",
       "      <td>[]</td>\n",
       "      <td>[пока, хватит, закончим разговор, мне пора]</td>\n",
       "      <td>[пока(((-)|( ))пока){0,1}, хватит ((болтать)|(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>repeat</td>\n",
       "      <td>[]</td>\n",
       "      <td>[повтори( еще раз){0,1}( пожалуйста){0,1}, ((м...</td>\n",
       "      <td>[повтори( еще раз){0,1}( пожалуйста){0,1}, ((м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>yes</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((да)|(конечно)|(разумеется)|(точно)|(согласе...</td>\n",
       "      <td>[((да)|(конечно)|(разумеется)|(точно)|(согласе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((нет)|(нее)|(неа)|(ни за что)|(ни в коем слу...</td>\n",
       "      <td>[((нет)|(нее)|(неа)|(ни за что)|(ни в коем слу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>what_is_your_name</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((представься)|(представь себя)), у тебя есть...</td>\n",
       "      <td>[((представься)|(представь себя)), у тебя есть...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>where_are_you_from</td>\n",
       "      <td>[]</td>\n",
       "      <td>[откуда ((ты)|(вы))( родом){0,1}, ((какая)|(ка...</td>\n",
       "      <td>[откуда ((ты)|(вы))( родом){0,1}, ((какая)|(ка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>what_can_you_do</td>\n",
       "      <td>[]</td>\n",
       "      <td>[что ты ((умеешь)|(можешь)|(способна)|(способе...</td>\n",
       "      <td>[.*что ты ((умеешь)|(можешь)|(способна)|(спосо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>choose_topic</td>\n",
       "      <td>[]</td>\n",
       "      <td>[о чем(( ты)|( мы)){0,1} ((можем)|(можешь)|(хо...</td>\n",
       "      <td>[о чем(( ты)|( мы)){0,1} ((можем)|(можешь)|(хо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>who_made_you</td>\n",
       "      <td>[]</td>\n",
       "      <td>[кто(( тебя)|( тобой)){0,1} ((сделал)|(создал)...</td>\n",
       "      <td>[кто(( тебя)|( тобой)){0,1} ((сделал)|(создал)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>what_is_your_job</td>\n",
       "      <td>[]</td>\n",
       "      <td>[((какой)|(какая)) ((у тебя)|(твоя)) ((професс...</td>\n",
       "      <td>[((какой)|(какая)) ((у тебя)|(твоя)) ((професс...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    intent_id                 intent_name sample_utterances  \\\n",
       "0           0  what_are_you_talking_about                []   \n",
       "1           1             topic_switching                []   \n",
       "2           2             lets_chat_about                []   \n",
       "3           3                        exit                []   \n",
       "4           4                      repeat                []   \n",
       "5           5                         yes                []   \n",
       "6           6                          no                []   \n",
       "7           7           what_is_your_name                []   \n",
       "8           8          where_are_you_from                []   \n",
       "9           9             what_can_you_do                []   \n",
       "10         10                choose_topic                []   \n",
       "11         11                who_made_you                []   \n",
       "12         12            what_is_your_job                []   \n",
       "\n",
       "                                  regexp_for_sampling  \\\n",
       "0   [о ((чем)|(чём)) ты( говоришь){0,1}( вообще){0...   \n",
       "1   [((хватит)|(прекрати)|(не хочу)|(не хочу больш...   \n",
       "2   [((можем)|(можешь)|(давай))(( мы)|( ты)|( я)){...   \n",
       "3         [пока, хватит, закончим разговор, мне пора]   \n",
       "4   [повтори( еще раз){0,1}( пожалуйста){0,1}, ((м...   \n",
       "5   [((да)|(конечно)|(разумеется)|(точно)|(согласе...   \n",
       "6   [((нет)|(нее)|(неа)|(ни за что)|(ни в коем слу...   \n",
       "7   [((представься)|(представь себя)), у тебя есть...   \n",
       "8   [откуда ((ты)|(вы))( родом){0,1}, ((какая)|(ка...   \n",
       "9   [что ты ((умеешь)|(можешь)|(способна)|(способе...   \n",
       "10  [о чем(( ты)|( мы)){0,1} ((можем)|(можешь)|(хо...   \n",
       "11  [кто(( тебя)|( тобой)){0,1} ((сделал)|(создал)...   \n",
       "12  [((какой)|(какая)) ((у тебя)|(твоя)) ((професс...   \n",
       "\n",
       "                                      regexp_as_rules  \n",
       "0   [о ((чем)|(чём)) ты( говоришь){0,1}( вообще){0...  \n",
       "1   [((хватит)|(прекрати)|(не хочу)|(не хочу больш...  \n",
       "2   [((можем)|(можешь)|(давай))(( мы)|( ты)|( я)){...  \n",
       "3   [пока(((-)|( ))пока){0,1}, хватит ((болтать)|(...  \n",
       "4   [повтори( еще раз){0,1}( пожалуйста){0,1}, ((м...  \n",
       "5   [((да)|(конечно)|(разумеется)|(точно)|(согласе...  \n",
       "6   [((нет)|(нее)|(неа)|(ни за что)|(ни в коем слу...  \n",
       "7   [((представься)|(представь себя)), у тебя есть...  \n",
       "8   [откуда ((ты)|(вы))( родом){0,1}, ((какая)|(ка...  \n",
       "9   [.*что ты ((умеешь)|(можешь)|(способна)|(спосо...  \n",
       "10  [о чем(( ты)|( мы)){0,1} ((можем)|(можешь)|(хо...  \n",
       "11  [кто(( тебя)|( тобой)){0,1} ((сделал)|(создал)...  \n",
       "12  [((какой)|(какая)) ((у тебя)|(твоя)) ((професс...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_ru_records = convert_dream(ru_dream)\n",
    "pd.DataFrame.from_records(dream_ru_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(dream_ru_records, open('../data/intent_records/ru_dream.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## banking77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://huggingface.co/datasets/PolyAI/banking77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voorhs/.pyenv/versions/3.10.14/envs/.autointent-dev/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "banking77 = load_dataset('PolyAI/banking77')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10003\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3080\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I am still waiting on my card?', 'label': 11}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking77['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget https://huggingface.co/datasets/PolyAI/banking77/resolve/main/dataset_infos.json -O ../data/banking77_info.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### intent records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking77_info = json.load(open('../data/banking77_info.json'))\n",
    "intent_names = banking77_info['default']['features']['label']['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_banking77(banking77_train, shots_per_intent, intent_names):\n",
    "    all_labels = sorted(banking77_train.unique('label'))\n",
    "    assert all_labels == list(range(len(intent_names)))\n",
    "\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': name,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i, name in enumerate(intent_names)]\n",
    "\n",
    "\n",
    "    for b77_batch in banking77_train.iter(batch_size=16, drop_last_batch=False):\n",
    "        for txt, intent_id in zip(b77_batch['text'], b77_batch['label']):\n",
    "            target_list = res[intent_id]['sample_utterances']\n",
    "            if len(target_list) >= shots_per_intent:\n",
    "                continue\n",
    "            target_list.append(txt)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking77_records = convert_banking77(banking77['train'], shots_per_intent=5, intent_names=intent_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': 'activate_my_card',\n",
       " 'sample_utterances': [\"Please help me with my card.  It won't activate.\",\n",
       "  'I tired but an unable to activate my card.',\n",
       "  'I want to start using my card.',\n",
       "  'How do I verify my new card?',\n",
       "  \"I tried activating my plug-in and it didn't piece of work\"],\n",
       " 'regexp_for_sampling': [],\n",
       " 'regexp_as_rules': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banking77_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(banking77_records, open('../data/intent_records/banking77.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utterance records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': 'activate_my_card',\n",
       " 'sample_utterances': [\"Please help me with my card.  It won't activate.\",\n",
       "  'I tired but an unable to activate my card.',\n",
       "  'I want to start using my card.',\n",
       "  'How do I verify my new card?',\n",
       "  \"I tried activating my plug-in and it didn't piece of work\"],\n",
       " 'regexp_for_sampling': [],\n",
       " 'regexp_as_rules': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "banking77_records = json.load(open('../data/intent_records/banking77.json'))\n",
    "ru_banking77_records = json.load(open('../data/intent_records/ru_banking77.json'))\n",
    "banking77_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utterance_records(intent_records):\n",
    "    res = []\n",
    "    for rec in intent_records:\n",
    "        for utt in rec['sample_utterances']:\n",
    "            res.append(dict(\n",
    "                intent_id=rec['intent_id'],\n",
    "                intent_name=rec['intent_name'],\n",
    "                utterance=utt\n",
    "            ))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "banking77_utterance_records = get_utterance_records(banking77_records)\n",
    "ru_banking77_utterance_records = get_utterance_records(ru_banking77_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(banking77_utterance_records, open('../data/utterance_records/banking77.json', 'w'), indent=4, ensure_ascii=False)\n",
    "json.dump(ru_banking77_utterance_records, open('../data/utterance_records/ru_banking77.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## russian banking77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://github.com/LadaNikitina/RuBanking77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '../data/RuBanking77'...\n",
      "Username for 'https://github.com': ^C\n"
     ]
    }
   ],
   "source": [
    "# ! git clone https://github.com/LadaNikitina/RuBanking77 ../data/RuBanking77\n",
    "# ! rm -rf ../data/RuBanking77/.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10003\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3080\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "rubanking77 = load_from_disk('../data/RuBanking77')\n",
    "rubanking77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Я все еще жду свою карту?', 'label': 11}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubanking77['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubanking77_records = convert_banking77(rubanking77['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': 'activate_my_card',\n",
       " 'sample_utterances': ['Пожалуйста, помогите мне с моей картой. Она не активируется.',\n",
       "  'Я устал, но не могу активировать свою карту.',\n",
       "  'Я хочу начать пользоваться своей картой.',\n",
       "  'Как мне проверить мою новую карту?',\n",
       "  'Я попытался активировать свой плагин, и это не сработало.'],\n",
       " 'regexp_for_sampling': [],\n",
       " 'regexp_as_rules': []}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubanking77_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(rubanking77_records, open('../data/intent_records/ru_banking77.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clinc150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2541143747714190ad4465dd44360258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/497 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3703154ba6498180e0da44f1702c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f6a4e31e544adaba6fef58d0848aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/212k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abd666238cd84468aa5ad4f9a1c3117e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/610k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73031d840684ca3b77ebda0abcee740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/15200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf3e4dac1e34926857afd6f21c70e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20543f3a9c940c4b8bd96827fe02e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7900 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['data', 'labels', 'domain', 'generalisation'],\n",
       "        num_rows: 15200\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['data', 'labels', 'domain', 'generalisation'],\n",
       "        num_rows: 3200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['data', 'labels', 'domain', 'generalisation'],\n",
       "        num_rows: 7900\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "clinc150 = load_dataset(\"cmaldona/All-Generalization-OOD-CLINC150\")\n",
    "clinc150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['accept_reservations',\n",
       " 'account_blocked',\n",
       " 'alarm',\n",
       " 'application_status',\n",
       " 'apr']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_names = sorted(clinc150['train'].unique('labels'))\n",
    "print(len(intent_names))\n",
    "intent_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_clinc150(clinc150_train, shots_per_intent):\n",
    "    intent_names = sorted(clinc150_train.unique('labels'))\n",
    "    name_to_id = dict(zip(intent_names, range(len(intent_names))))\n",
    "\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': name,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i, name in enumerate(intent_names)]\n",
    "\n",
    "\n",
    "    for batch in clinc150_train.iter(batch_size=16, drop_last_batch=False):\n",
    "        for txt, name in zip(batch['data'], batch['labels']):\n",
    "            intent_id = name_to_id[name]\n",
    "            target_list = res[intent_id]['sample_utterances']\n",
    "            if len(target_list) >= shots_per_intent:\n",
    "                continue\n",
    "            target_list.append(txt)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinc150_records = convert_clinc150(clinc150['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': 'accept_reservations',\n",
       " 'sample_utterances': ['can i make a reservation for redrobin',\n",
       "  'is it possible to make a reservation at redrobin',\n",
       "  'does redrobin take reservations',\n",
       "  'are reservations taken at redrobin',\n",
       "  'does redrobin do reservations'],\n",
       " 'regexp_for_sampling': [],\n",
       " 'regexp_as_rules': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinc150_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(clinc150_records, open('../data/intent_records/clinc150.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## russian clinc150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/LadaNikitina/clinc150 ../data/RuClinc150\n",
    "# ! rm -rf ../data/RuClinc150/.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 15250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 5500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 3100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ruclinc150 = load_from_disk('../data/RuClinc150')\n",
    "ruclinc150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Какое выражение я бы использовал, чтобы сказать, что я люблю тебя, если бы я был итальянцем?',\n",
       " 'intent': 61}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruclinc150['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ruclinc150(clinc150_train, shots_per_intent):\n",
    "    all_labels = sorted(clinc150_train.unique('intent'))\n",
    "    assert all_labels == list(range(151))\n",
    "\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': None,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i in range(151)]\n",
    "\n",
    "\n",
    "    for batch in clinc150_train.iter(batch_size=16, drop_last_batch=False):\n",
    "        for txt, intent_id in zip(batch['text'], batch['intent']):\n",
    "            target_list = res[intent_id]['sample_utterances']\n",
    "            if len(target_list) >= shots_per_intent:\n",
    "                continue\n",
    "            target_list.append(txt)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruclinc150_records = convert_ruclinc150(ruclinc150['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(ruclinc150_records, open('../data/intent_records/ru_clinc150.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6eeb5a507b40eaa85631a143f7bd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/426 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9752a067f48d4aa29fc50f1eb170e162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/370k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84c9246be3c47fc931205d9e461fcfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/45.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578f12e17fd045c68805d7f4048ac1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/13084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27fc208fb884d22a0f2e6c21425d6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'category'],\n",
       "        num_rows: 13084\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'category'],\n",
       "        num_rows: 1400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "snips = load_dataset(\"benayas/snips\")\n",
    "snips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AddToPlaylist',\n",
       " 'BookRestaurant',\n",
       " 'GetWeather',\n",
       " 'PlayMusic',\n",
       " 'RateBook',\n",
       " 'SearchCreativeWork',\n",
       " 'SearchScreeningEvent']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_names = sorted(snips['train'].unique('category'))\n",
    "print(len(intent_names))\n",
    "intent_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_snips(snips_train, shots_per_intent):\n",
    "    intent_names = sorted(snips_train.unique('category'))\n",
    "    name_to_id = dict(zip(intent_names, range(len(intent_names))))\n",
    "\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': name,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i, name in enumerate(intent_names)]\n",
    "\n",
    "\n",
    "    for batch in snips_train.iter(batch_size=16, drop_last_batch=False):\n",
    "        for txt, name in zip(batch['text'], batch['category']):\n",
    "            intent_id = name_to_id[name]\n",
    "            target_list = res[intent_id]['sample_utterances']\n",
    "            if len(target_list) >= shots_per_intent:\n",
    "                continue\n",
    "            target_list.append(txt)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "snips_records = convert_snips(snips['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(snips_records, open('../data/intent_records/snips.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## russian Snips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/LadaNikitina/Snips ../data/RuSnips\n",
    "# ! rm -rf ../data/RuSnips/.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 13784\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 700\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "rusnips = load_from_disk('../data/RuSnips')\n",
    "rusnips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Добавьте еще одну песню в плейлист Cita Romántica.',\n",
       " 'intent': 'add_to_playlist'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusnips['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['add_to_playlist',\n",
       " 'book_restaurant',\n",
       " 'get_weather',\n",
       " 'play_music',\n",
       " 'rate_book',\n",
       " 'search_creative_work',\n",
       " 'search_screening_event']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rusnips['train'].unique('intent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rusnips(snips_train, shots_per_intent):\n",
    "    intent_names = sorted(snips_train.unique('intent'))\n",
    "    name_to_id = dict(zip(intent_names, range(len(intent_names))))\n",
    "\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': name,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i, name in enumerate(intent_names)]\n",
    "\n",
    "\n",
    "    for batch in snips_train.iter(batch_size=16, drop_last_batch=False):\n",
    "        for txt, name in zip(batch['text'], batch['intent']):\n",
    "            intent_id = name_to_id[name]\n",
    "            target_list = res[intent_id]['sample_utterances']\n",
    "            if len(target_list) >= shots_per_intent:\n",
    "                continue\n",
    "            target_list.append(txt)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rusnips_records = convert_rusnips(rusnips['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(rusnips_records, open('../data/intent_records/ru_snips.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hwu64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://github.com/jianguoz/Few-Shot-Intent-Detection/tree/main/Datasets/HWU64/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alarm_query', 'alarm_query', 'alarm_query', 'alarm_query', 'alarm_query']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hwu64_labels = open(\"../data/hwu_assets/label.txt\").read().split('\\n')[:-1]\n",
    "print(len(hwu64_labels))\n",
    "hwu64_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['what alarms do i have set right now',\n",
       " 'checkout today alarm of meeting',\n",
       " 'report alarm settings',\n",
       " 'see see for me the alarms that you have set tomorrow morning',\n",
       " 'is there an alarm for ten am']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hwu64_utterances = open(\"../data/hwu_assets/seq.in\").read().split('\\n')[:-1]\n",
    "print(len(hwu64_utterances))\n",
    "hwu64_utterances[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(hwu64_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hwu64(hwu_utterances, hwu_labels, shots_per_intent):\n",
    "    intent_names = sorted(set(hwu_labels))\n",
    "    name_to_id = dict(zip(intent_names, range(len(intent_names))))\n",
    "\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': name,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i, name in enumerate(intent_names)]\n",
    "\n",
    "    for txt, name in zip(hwu_utterances, hwu_labels):\n",
    "        intent_id = name_to_id[name]\n",
    "        target_list = res[intent_id]['sample_utterances']\n",
    "        if len(target_list) >= shots_per_intent:\n",
    "            continue\n",
    "        target_list.append(txt)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwu64_records = convert_hwu64(hwu64_utterances, hwu64_labels, shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(hwu64_records, open('../data/intent_records/hwu64.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## russian hwu64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/LadaNikitina/HWU64 ../data/RuHWU64\n",
    "# ! rm -rf ../data/RuHWU64/.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'intent'],\n",
       "        num_rows: 25606\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ruhwu64 = load_from_disk('../data/RuHWU64')\n",
    "ruhwu64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Разбуди меня в 5 утра на этой неделе', 'intent': 'set'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruhwu64['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['addcontact', 'affirm', 'audiobook', 'cleaning', 'coffee']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_names = sorted(set(ruhwu64['train'].unique('intent')))\n",
    "print(len(intent_names))\n",
    "intent_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ruhwu64(hwu64_train, shots_per_intent):\n",
    "    intent_names = sorted(hwu64_train.unique('intent'))\n",
    "    name_to_id = dict(zip(intent_names, range(len(intent_names))))\n",
    "\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': name,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i, name in enumerate(intent_names)]\n",
    "\n",
    "\n",
    "    for batch in hwu64_train.iter(batch_size=16, drop_last_batch=False):\n",
    "        for txt, name in zip(batch['text'], batch['intent']):\n",
    "            intent_id = name_to_id[name]\n",
    "            target_list = res[intent_id]['sample_utterances']\n",
    "            if len(target_list) >= shots_per_intent:\n",
    "                continue\n",
    "            target_list.append(txt)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruhwu64_records = convert_ruhwu64(ruhwu64['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(ruhwu64_records, open('../data/intent_records/ru_hwu64.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## russian Minds14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8795ee3d794e29a4391e9b3020d9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "        num_rows: 539\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ruminds14 = load_dataset(\"PolyAI/minds14\", 'ru-RU')\n",
    "ruminds14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/home/voorhs/.cache/huggingface/datasets/downloads/extracted/f8075d4661a5d714b98ee4adbe7d239eb1a69d19d3cd7fa9cd42aeb27cab93c3/ru-RU~LATEST_TRANSACTIONS/6030093cbb1e6d0fbce93a74.wav',\n",
       " 'audio': {'path': '/home/voorhs/.cache/huggingface/datasets/downloads/extracted/f8075d4661a5d714b98ee4adbe7d239eb1a69d19d3cd7fa9cd42aeb27cab93c3/ru-RU~LATEST_TRANSACTIONS/6030093cbb1e6d0fbce93a74.wav',\n",
       "  'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00048828,\n",
       "         -0.00073242, -0.00073242]),\n",
       "  'sampling_rate': 8000},\n",
       " 'transcription': 'Здравствуйте я бы хотела пересмотреть свои предыдущие последние операции которые проходили по моей карте прямым помимо ему счёту Покажите пожалуйста операции последних трёх месяцев',\n",
       " 'english_transcription': 'Hello, I would like to review my previous last transactions that took place on my card directly in addition to his account. Please show the transactions of the last three months',\n",
       " 'intent_class': 12,\n",
       " 'lang_id': 12}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruminds14[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ruminds14[\"train\"].unique('intent_class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ruminds14(minds14_train, shots_per_intent):\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': None,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i in range(14)]\n",
    "\n",
    "\n",
    "    for batch in minds14_train.iter(batch_size=16, drop_last_batch=False):\n",
    "        for txt, intent_id in zip(batch['transcription'], batch['intent_class']):\n",
    "            target_list = res[intent_id]['sample_utterances']\n",
    "            if len(target_list) >= shots_per_intent:\n",
    "                continue\n",
    "            target_list.append(txt)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruminds14_records = convert_ruminds14(ruminds14['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': None,\n",
       " 'sample_utterances': ['Здравствуйте я хотел бы узнать Могу ли я использовать свою карту за границей и нужно мне для этого предупредить Мой Банк Спасибо',\n",
       "  'Здравствуйте какая комиссия будет если я буду использовать карту свою заграницы',\n",
       "  'Здравствуйте Через несколько дней я уезжаю в швецию на целый месяц я хотел бы узнать Могу ли я платить моей карты Спасибо',\n",
       "  'Здравствуйте я уезжаю на несколько недель заграницу и хотела бы узнать Могу ли я пользоваться твоей картой там Я бы хотела оплачивать покупки в Америке Нужно ли мне что-нибудь для этого делать',\n",
       "  'Здравствуйте мне хотелось бы задать вам один вопрос я уезжаю в отпуск и мне нужно уточнить работать будет ли моя кредитная карточка За границей'],\n",
       " 'regexp_for_sampling': [],\n",
       " 'regexp_as_rules': []}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruminds14_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(ruminds14_records, open('../data/intent_records/ru_minds14.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minds14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_minds14(minds14_train, shots_per_intent):\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': None,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i in range(14)]\n",
    "\n",
    "\n",
    "    for batch in minds14_train.iter(batch_size=16, drop_last_batch=False):\n",
    "        for txt, intent_id in zip(batch['english_transcription'], batch['intent_class']):\n",
    "            target_list = res[intent_id]['sample_utterances']\n",
    "            if len(target_list) >= shots_per_intent:\n",
    "                continue\n",
    "            target_list.append(txt)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "minds14_records = convert_minds14(ruminds14['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': None,\n",
       " 'sample_utterances': ['Hello, I would like to know if I can use my card abroad and I need to warn My Bank for this. Thank you',\n",
       "  'Hello, what will be the commission if I use my card abroad',\n",
       "  'Hello In a few days I am leaving for sweden for a whole month I would like to know if I can pay with my card Thank you',\n",
       "  'Hello, I am going abroad for a few weeks and would like to know Can I use your card there I would like to pay for purchases in America Do I need to do anything for this',\n",
       "  'Hello, I would like to ask you one question, I am going on vacation and I need to clarify whether my credit card will work abroad'],\n",
       " 'regexp_for_sampling': [],\n",
       " 'regexp_as_rules': []}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds14_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(minds14_records, open('../data/intent_records/minds14.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f389e606b554e078096956d4a777222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a38134170ba4958b052c2f70a8681a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30735a193e1644ceb8b445dd25c34d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59926fda045444aeb9efecb41098b862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cf5c3dd57b4050924a7cbca003da3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/187k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709760dde49744a68bff556f74241556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/54.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b736901731da4b369c5fe52fbe121e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/38.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9613c2088548cebc2c6ac791a6045b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9199d7f211e47f6999b38a058d19a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2518b85f40b04dca89fe20d84111cda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2033 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'label', 'label_text', 'text', 'lang'],\n",
       "        num_rows: 11514\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'label', 'label_text', 'text', 'lang'],\n",
       "        num_rows: 2974\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'label', 'label_text', 'text', 'lang'],\n",
       "        num_rows: 2033\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "massive = load_dataset(\"mteb/amazon_massive_intent\", 'en')\n",
    "massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'label': 'alarm_set',\n",
       " 'label_text': 'alarm_set',\n",
       " 'text': 'wake me up at nine am on friday',\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massive['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alarm_query',\n",
       " 'alarm_remove',\n",
       " 'alarm_set',\n",
       " 'audio_volume_down',\n",
       " 'audio_volume_mute']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_names = sorted(massive['train'].unique('label'))\n",
    "print(len(intent_names))\n",
    "intent_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_massive(massive_train, shots_per_intent):\n",
    "    intent_names = sorted(massive_train.unique('label'))\n",
    "    name_to_id = dict(zip(intent_names, range(len(intent_names))))\n",
    "\n",
    "    res = [{\n",
    "        'intent_id': i,\n",
    "        'intent_name': name,\n",
    "        'sample_utterances': [],\n",
    "        'regexp_for_sampling': [],\n",
    "        'regexp_as_rules': []\n",
    "    } for i, name in enumerate(intent_names)]\n",
    "\n",
    "\n",
    "    for batch in massive_train.iter(batch_size=16, drop_last_batch=False):\n",
    "        for txt, name in zip(batch['text'], batch['label']):\n",
    "            intent_id = name_to_id[name]\n",
    "            target_list = res[intent_id]['sample_utterances']\n",
    "            if len(target_list) >= shots_per_intent:\n",
    "                continue\n",
    "            target_list.append(txt)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "massive_records = convert_massive(massive['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': 'alarm_query',\n",
       " 'sample_utterances': ['please list active alarms',\n",
       "  'show me the alarms i set',\n",
       "  'do i have any alarms',\n",
       "  'show alarms',\n",
       "  'do i have an alarm set for morning flight'],\n",
       " 'regexp_for_sampling': [],\n",
       " 'regexp_as_rules': []}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "massive_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(massive_records, open('../data/intent_records/massive.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## russian Massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16a0d7a7c514a97a494066a490c6172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0b28d506a24090ac74c59acbad7277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfe1527816f47a69bb5c38bfd3c996a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5196af6645e2437599cc7a6d0a15745b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/262k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d59a289f8964af28e26d2f6c7d1140d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/73.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b9cd3621bd465aafffc55b25b671de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/51.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb48901082e4711ad72fa008d3a0e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/11514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95329ddd27da46d1b664f5b121bcf865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dece0b2fec4ce9aa6209a79aae616a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/2033 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'label', 'label_text', 'text', 'lang'],\n",
       "        num_rows: 11514\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'label', 'label_text', 'text', 'lang'],\n",
       "        num_rows: 2974\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'label', 'label_text', 'text', 'lang'],\n",
       "        num_rows: 2033\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "rumassive = load_dataset(\"mteb/amazon_massive_intent\", 'ru')\n",
    "rumassive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'label': 'alarm_set',\n",
       " 'label_text': 'alarm_set',\n",
       " 'text': 'разбуди меня в девять утра в пятницу',\n",
       " 'lang': 'ru'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumassive['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "rumassive_records = convert_massive(rumassive['train'], shots_per_intent=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent_id': 0,\n",
       " 'intent_name': 'alarm_query',\n",
       " 'sample_utterances': ['пожалуйста список активных будильников',\n",
       "  'покажи мне будильники которые я установил',\n",
       "  'у меня есть какие-то будильники',\n",
       "  'покажи будильники',\n",
       "  'имею ли я будильник на утренний рейс'],\n",
       " 'regexp_for_sampling': [],\n",
       " 'regexp_as_rules': []}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumassive_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(rumassive_records, open('../data/intent_records/ru_massive.json', 'w'), indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".autointent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
